<<<<<<< HEAD
{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Giles\\miniconda3\\envs\\visiontf\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.5)\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Ensure memory growth is enabled\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n","Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n","  Quadro M1200, compute capability 5.0\n","See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n","If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n","WARNING:tensorflow:From c:\\Users\\Giles\\miniconda3\\envs\\visiontf\\lib\\site-packages\\tensorflow\\python\\keras\\mixed_precision\\loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"]}],"source":["# Mixed precision\n","from tensorflow.keras.mixed_precision import experimental as mixed_precision\n","policy = mixed_precision.Policy('mixed_float16')\n","mixed_precision.set_policy(policy)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Define paths and parameters\n","dir_path = 'data/images/'\n","train_path = 'data/images/train/'\n","classes = ['0', '1']\n","image_size = (224, 224)\n","batch_size = 32\n","num_epochs = 10  # Increase number of epochs\n","\n","# Data augmentation and normalization\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 3221 images belonging to 2 classes.\n"]}],"source":["# Load and prepare the train and validation datasets\n","train_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    classes=classes,\n","    subset='training'\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 805 images belonging to 2 classes.\n"]}],"source":["validation_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    classes=classes,\n","    subset='validation'\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Define the model architecture\n","base_model = tf.keras.applications.ResNet50(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(224, 224, 3)\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for layer in base_model.layers[:-10]:  # Unfreeze last 10 layers\n","    layer.trainable = True"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["x = layers.GlobalAveragePooling2D()(base_model.output)\n","x = layers.Dense(256, activation='relu')(x)\n","x = layers.Dropout(0.5)(x)\n","output = layers.Dense(len(classes), activation='softmax')(x)\n","\n","model = tf.keras.models.Model(base_model.input, output)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n","  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Giles\\miniconda3\\envs\\visiontf\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  warnings.warn(\n"]}],"source":["# Compile the model with a lower learning rate\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Clear any previous session to free memory\n","from tensorflow.keras import backend as K\n","K.clear_session()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","101/101 [==============================] - 252s 2s/step - loss: 0.3603 - accuracy: 0.8389 - val_loss: 2.4417 - val_accuracy: 0.4124\n","Epoch 2/10\n","101/101 [==============================] - 170s 2s/step - loss: 0.1881 - accuracy: 0.9249 - val_loss: 1.3361 - val_accuracy: 0.4124\n","Epoch 3/10\n","101/101 [==============================] - 176s 2s/step - loss: 0.1361 - accuracy: 0.9478 - val_loss: 3.4495 - val_accuracy: 0.4124\n","Epoch 4/10\n","101/101 [==============================] - 192s 2s/step - loss: 0.1143 - accuracy: 0.9559 - val_loss: 1.8808 - val_accuracy: 0.4124\n","Epoch 5/10\n","101/101 [==============================] - 180s 2s/step - loss: 0.0970 - accuracy: 0.9643 - val_loss: 2.0536 - val_accuracy: 0.4124\n","Epoch 6/10\n","101/101 [==============================] - 178s 2s/step - loss: 0.0787 - accuracy: 0.9730 - val_loss: 2.0362 - val_accuracy: 0.4124\n","Epoch 7/10\n","101/101 [==============================] - 173s 2s/step - loss: 0.0725 - accuracy: 0.9758 - val_loss: 1.2197 - val_accuracy: 0.4547\n","Epoch 8/10\n","101/101 [==============================] - 187s 2s/step - loss: 0.0652 - accuracy: 0.9758 - val_loss: 0.8491 - val_accuracy: 0.6547\n","Epoch 9/10\n","101/101 [==============================] - 177s 2s/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.4205 - val_accuracy: 0.8248\n","Epoch 10/10\n","101/101 [==============================] - 183s 2s/step - loss: 0.0644 - accuracy: 0.9773 - val_loss: 0.4242 - val_accuracy: 0.8894\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x2672cfe3d90>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model with more epochs\n","model.fit(\n","    train_generator,\n","    epochs=num_epochs,\n","    validation_data=validation_generator\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.5080745341614907\n"]}],"source":["# Evaluate the model\n","validation_steps = validation_generator.samples // batch_size + 1\n","predictions = model.predict(validation_generator, steps=validation_steps)\n","predicted_classes = tf.argmax(predictions, axis=1)\n","true_classes = validation_generator.classes\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","\n","print(\"Test Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the trained model to disk\n","model.save('trained_model.h5')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP/wUD0O0uHeUK2BeHgcH9C","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
=======
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import accuracy_score\n","\n","# Define paths and parameters\n","dir_path = 'data/images/'\n","train_path = 'data/images/train/'\n","classes = ['0', '1']\n","image_size = (224, 224)\n","batch_size = 32\n","num_epochs = 10  # Increase number of epochs\n","\n","# Data augmentation and normalization\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2\n",")\n","\n","# Load and prepare the train and validation datasets\n","train_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    classes=classes,\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    classes=classes,\n","    subset='validation'\n",")\n","\n","# Define the model architecture\n","base_model = tf.keras.applications.ResNet50(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(224, 224, 3)\n",")\n","\n","for layer in base_model.layers[:-10]:  # Unfreeze last 10 layers\n","    layer.trainable = True\n","\n","x = layers.GlobalAveragePooling2D()(base_model.output)\n","x = layers.Dense(256, activation='relu')(x)\n","x = layers.Dropout(0.5)(x)\n","output = layers.Dense(len(classes), activation='softmax')(x)\n","\n","model = tf.keras.models.Model(base_model.input, output)\n","\n","# Compile the model with a lower learning rate\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model with more epochs\n","model.fit(\n","    train_generator,\n","    epochs=num_epochs,\n","    validation_data=validation_generator\n",")\n","\n","# Evaluate the model\n","validation_steps = validation_generator.samples // batch_size + 1\n","predictions = model.predict(validation_generator, steps=validation_steps)\n","predicted_classes = tf.argmax(predictions, axis=1)\n","true_classes = validation_generator.classes\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","\n","print(\"Test Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the trained model to disk\n","model.save('trained_model.h5')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP/wUD0O0uHeUK2BeHgcH9C","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
>>>>>>> 26d8d225384b4ac7fc2010bb5a15cbe573327fe7
